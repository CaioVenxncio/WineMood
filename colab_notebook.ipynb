{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WineMood ‚Äì Classificador de Sentimentos para Avalia√ß√µes de Vinhos\n",
    "\n",
    "Este notebook implementa um sistema de classifica√ß√£o de sentimentos para avalia√ß√µes de vinhos usando t√©cnicas de Processamento de Linguagem Natural (NLP) e Deep Learning.\n",
    "\n",
    "## Objetivos\n",
    "- Analisar avalia√ß√µes textuais de vinhos\n",
    "- Classificar o sentimento como positivo, neutro ou negativo\n",
    "- Criar um modelo de Deep Learning para entender o contexto das avalia√ß√µes\n",
    "- Desenvolver uma interface web para teste em tempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o do Ambiente\n",
    "\n",
    "Primeiro, vamos instalar e importar as bibliotecas necess√°rias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Instalar bibliotecas necess√°rias\n",
    "!pip install kaggle nltk tensorflow pandas numpy matplotlib streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Bibliotecas para NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Bibliotecas para Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Configurar visualiza√ß√£o\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Verificar se GPU est√° dispon√≠vel\n",
    "print(\"GPU dispon√≠vel:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download e Carregamento do Dataset\n",
    "\n",
    "Vamos baixar o dataset de avalia√ß√µes de vinhos do Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configurar a API do Kaggle\n",
    "# Nota: Voc√™ precisa fazer upload do arquivo kaggle.json para o Colab\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Criar diret√≥rio para as credenciais do Kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Baixar o dataset\n",
    "!kaggle datasets download -d zynicide/wine-reviews\n",
    "!unzip wine-reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Carregar o dataset\n",
    "df = pd.read_csv('winemag-data-130k-v2.csv')\n",
    "\n",
    "# Exibir as primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explora√ß√£o e Pr√©-processamento de Dados\n",
    "\n",
    "Vamos explorar o dataset e preparar os dados para o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verificar informa√ß√µes do dataset\n",
    "print(\"Formato do dataset:\", df.shape)\n",
    "print(\"\\nInforma√ß√µes do dataset:\")\n",
    "df.info()\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verificar estat√≠sticas descritivas\n",
    "print(\"Estat√≠sticas descritivas da pontua√ß√£o:\")\n",
    "df['points'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizar a distribui√ß√£o de pontua√ß√µes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['points'], bins=20, kde=True)\n",
    "plt.title('Distribui√ß√£o de Pontua√ß√µes de Vinhos')\n",
    "plt.xlabel('Pontua√ß√£o')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filtrar apenas as colunas necess√°rias e remover valores nulos\n",
    "df_filtered = df[['description', 'points']].dropna()\n",
    "print(f\"Formato ap√≥s filtragem: {df_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criar r√≥tulos de sentimento baseados na pontua√ß√£o\n",
    "def create_sentiment_label(points):\n",
    "    if points >= 90:\n",
    "        return 2  # Positivo\n",
    "    elif points >= 80:\n",
    "        return 1  # Neutro\n",
    "    else:\n",
    "        return 0  # Negativo\n",
    "\n",
    "df_filtered['sentiment'] = df_filtered['points'].apply(create_sentiment_label)\n",
    "\n",
    "# Verificar a distribui√ß√£o de sentimentos\n",
    "sentiment_counts = df_filtered['sentiment'].value_counts()\n",
    "print(\"Distribui√ß√£o de sentimentos:\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Visualizar a distribui√ß√£o\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='sentiment', data=df_filtered, palette=['red', 'gray', 'green'])\n",
    "plt.title('Distribui√ß√£o de Sentimentos')\n",
    "plt.xlabel('Sentimento (0: Negativo, 1: Neutro, 2: Positivo)')\n",
    "plt.ylabel('Contagem')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©-processamento de Texto\n",
    "\n",
    "Vamos limpar e preparar o texto para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Baixar stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fun√ß√£o para pr√©-processar o texto\n",
    "def preprocess_text(text):\n",
    "    # Converter para min√∫sculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remover pontua√ß√£o e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remover stopwords\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Aplicar pr√©-processamento\n",
    "df_filtered['processed_text'] = df_filtered['description'].apply(preprocess_text)\n",
    "\n",
    "# Exibir exemplos de texto original e processado\n",
    "examples = df_filtered[['description', 'processed_text', 'sentiment']].sample(5)\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepara√ß√£o dos Dados para o Modelo\n",
    "\n",
    "Vamos tokenizar e padronizar os textos para alimentar o modelo de Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definir par√¢metros\n",
    "MAX_NUM_WORDS = 10000  # Tamanho do vocabul√°rio\n",
    "MAX_SEQUENCE_LENGTH = 100  # Comprimento m√°ximo da sequ√™ncia\n",
    "EMBEDDING_DIM = 100  # Dimens√£o do embedding\n",
    "\n",
    "# Criar tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(df_filtered['processed_text'])\n",
    "\n",
    "# Converter textos para sequ√™ncias\n",
    "sequences = tokenizer.texts_to_sequences(df_filtered['processed_text'])\n",
    "\n",
    "# Padronizar sequ√™ncias\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# Verificar formato dos dados\n",
    "print(f\"Formato das sequ√™ncias padronizadas: {padded_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preparar r√≥tulos para classifica√ß√£o multiclasse\n",
    "labels = tf.keras.utils.to_categorical(df_filtered['sentiment'], num_classes=3)\n",
    "print(f\"Formato dos r√≥tulos: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dividir em conjuntos de treino e teste (80/20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treino: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de teste: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Constru√ß√£o e Treinamento do Modelo\n",
    "\n",
    "Vamos criar um modelo de Deep Learning com camadas de Embedding e LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definir o modelo\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: negativo, neutro, positivo\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definir callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avalia√ß√£o do Modelo\n",
    "\n",
    "Vamos avaliar o desempenho do modelo no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Carregar o melhor modelo\n",
    "best_model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Acur√°cia no conjunto de teste: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizar o hist√≥rico de treinamento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gr√°fico de acur√°cia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Valida√ß√£o')\n",
    "plt.title('Acur√°cia do Modelo')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Acur√°cia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Gr√°fico de perda\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Valida√ß√£o')\n",
    "plt.title('Perda do Modelo')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fazer predi√ß√µes no conjunto de teste\n",
    "y_pred_proba = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matriz de confus√£o\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negativo', 'Neutro', 'Positivo'],\n",
    "            yticklabels=['Negativo', 'Neutro', 'Positivo'])\n",
    "plt.title('Matriz de Confus√£o')\n",
    "plt.xlabel('Predito')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "# Relat√≥rio de classifica√ß√£o\n",
    "print(\"Relat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['Negativo', 'Neutro', 'Positivo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An√°lise de Exemplos Incorretos\n",
    "\n",
    "Vamos analisar alguns exemplos que o modelo classificou incorretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identificar exemplos classificados incorretamente\n",
    "incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "print(f\"N√∫mero de exemplos classificados incorretamente: {len(incorrect_indices)}\")\n",
    "\n",
    "# Selecionar alguns exemplos incorretos aleatoriamente\n",
    "if len(incorrect_indices) > 0:\n",
    "    sample_size = min(5, len(incorrect_indices))\n",
    "    sample_indices = np.random.choice(incorrect_indices, size=sample_size, replace=False)\n",
    "    \n",
    "    # Recuperar os textos originais\n",
    "    original_texts = df_filtered['description'].values[np.where(df_filtered.index.isin(X_test[sample_indices]))[0]]\n",
    "    \n",
    "    # Exibir exemplos incorretos\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        true_label = ['Negativo', 'Neutro', 'Positivo'][y_true[idx]]\n",
    "        pred_label = ['Negativo', 'Neutro', 'Positivo'][y_pred[idx]]\n",
    "        print(f\"Exemplo {i+1}:\")\n",
    "        print(f\"Texto: {original_texts[i]}\")\n",
    "        print(f\"R√≥tulo real: {true_label}\")\n",
    "        print(f\"R√≥tulo predito: {pred_label}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Salvar o Modelo e o Tokenizer\n",
    "\n",
    "Vamos salvar o modelo treinado e o tokenizer para uso na aplica√ß√£o web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Salvar o modelo final\n",
    "best_model.save('model.h5')\n",
    "print(\"Modelo salvo como 'model.h5'\")\n",
    "\n",
    "# Salvar o tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tokenizer salvo como 'tokenizer.pickle'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Teste do Modelo com Exemplos\n",
    "\n",
    "Vamos testar o modelo com alguns exemplos de avalia√ß√µes de vinhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Fun√ß√£o para classificar o sentimento de um texto\n",
    "def classify_sentiment(text, model, tokenizer):\n",
    "    # Pr√©-processar o texto\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Tokenizar e padronizar\n",
    "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    \n",
    "    # Fazer a predi√ß√£o\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    sentiment_class = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    # Mapear para r√≥tulos de sentimento\n",
    "    sentiment_map = {0: \"Negativo\", 1: \"Neutro\", 2: \"Positivo\"}\n",
    "    sentiment = sentiment_map[sentiment_class]\n",
    "    \n",
    "    # Obter as probabilidades\n",
    "    probabilities = prediction[0]\n",
    "    \n",
    "    return sentiment, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exemplos de avalia√ß√µes de vinhos\n",
    "examples = [\n",
    "    \"Great complexity with floral aromas and a long finish.\",\n",
    "    \"This wine is average at best, with a short finish and little character.\",\n",
    "    \"Terrible wine, tastes like vinegar and has no depth.\",\n",
    "    \"Balanced acidity with notes of apple and pear, decent for the price.\",\n",
    "    \"Exceptional depth and complexity, with layers of dark fruit and spice.\"\n",
    "]\n",
    "\n",
    "# Testar o modelo com os exemplos\n",
    "for example in examples:\n",
    "    sentiment, probabilities = classify_sentiment(example, best_model, tokenizer)\n",
    "    print(f\"Texto: {example}\")\n",
    "    print(f\"Sentimento: {sentiment}\")\n",
    "    print(f\"Probabilidades: Negativo: {probabilities[0]:.4f}, Neutro: {probabilities[1]:.4f}, Positivo: {probabilities[2]:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prepara√ß√£o para a Interface Web\n",
    "\n",
    "Vamos preparar os arquivos necess√°rios para a aplica√ß√£o Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criar arquivo requirements.txt\n",
    "requirements = \"\"\"\n",
    "streamlit==1.22.0\n",
    "tensorflow==2.12.0\n",
    "nltk==3.8.1\n",
    "numpy==1.23.5\n",
    "pandas==1.5.3\n",
    "matplotlib==3.7.1\n",
    "\"\"\"\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements.strip())\n",
    "    \n",
    "print(\"Arquivo requirements.txt criado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Baixar arquivos para uso local\n",
    "from google.colab import files\n",
    "\n",
    "files.download('model.h5')\n",
    "files.download('tokenizer.pickle')\n",
    "files.download('requirements.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. C√≥digo da Aplica√ß√£o Streamlit\n",
    "\n",
    "Abaixo est√° o c√≥digo para a aplica√ß√£o Streamlit que pode ser salvo como `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "\n",
    "# Configura√ß√£o da p√°gina\n",
    "st.set_page_config(\n",
    "    page_title=\"WineMood - Sentiment Analyzer\",\n",
    "    page_icon=\"üç∑\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\",\n",
    "    menu_items={\n",
    "        'About': \"# WineMood - Analisador de Sentimentos para Avalia√ß√µes de Vinhos\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Aplicar tema escuro personalizado\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main {\n",
    "        background-color: #1E1E1E;\n",
    "        color: #FFFFFF;\n",
    "    }\n",
    "    .stTextInput > div > div > input {\n",
    "        background-color: #2D2D2D;\n",
    "        color: #FFFFFF;\n",
    "    }\n",
    "    .stButton>button {\n",
    "        background-color: #8A2BE2;\n",
    "        color: white;\n",
    "        font-weight: bold;\n",
    "        border-radius: 5px;\n",
    "        padding: 0.5rem 1rem;\n",
    "        border: none;\n",
    "    }\n",
    "    .stButton>button:hover {\n",
    "        background-color: #9370DB;\n",
    "    }\n",
    "    .positive {\n",
    "        color: #4CAF50;\n",
    "        font-weight: bold;\n",
    "        font-size: 24px;\n",
    "    }\n",
    "    .neutral {\n",
    "        color: #9E9E9E;\n",
    "        font-weight: bold;\n",
    "        font-size: 24px;\n",
    "    }\n",
    "    .negative {\n",
    "        color: #F44336;\n",
    "        font-weight: bold;\n",
    "        font-size: 24px;\n",
    "    }\n",
    "    .title {\n",
    "        font-size: 42px;\n",
    "        font-weight: bold;\n",
    "        text-align: center;\n",
    "        margin-bottom: 30px;\n",
    "        color: #FFFFFF;\n",
    "    }\n",
    "    .subtitle {\n",
    "        font-size: 24px;\n",
    "        font-weight: bold;\n",
    "        margin-bottom: 20px;\n",
    "        color: #FFFFFF;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Fun√ß√£o para carregar o modelo e o tokenizer\n",
    "@st.cache_resource\n",
    "def load_model_and_tokenizer():\n",
    "    try:\n",
    "        # Carregar o modelo\n",
    "        model = tf.keras.models.load_model('model.h5')\n",
    "        \n",
    "        # Carregar o tokenizer\n",
    "        with open('tokenizer.pickle', 'rb') as handle:\n",
    "            tokenizer = pickle.load(handle)\n",
    "            \n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erro ao carregar o modelo: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Fun√ß√£o para pr√©-processar o texto\n",
    "def preprocess_text(text, tokenizer, max_length=100):\n",
    "    # Converter para min√∫sculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remover pontua√ß√£o e caracteres especiais\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remover stopwords\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords')\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # Tokenizar e padronizar\n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "# Fun√ß√£o para classificar o sentimento\n",
    "def classify_sentiment(text, model, tokenizer):\n",
    "    # Pr√©-processar o texto\n",
    "    processed_text = preprocess_text(text, tokenizer)\n",
    "    \n",
    "    # Fazer a predi√ß√£o\n",
    "    prediction = model.predict(processed_text)\n",
    "    \n",
    "    # Obter a classe com maior probabilidade\n",
    "    sentiment_class = np.argmax(prediction, axis=1)[0]\n",
    "    \n",
    "    # Mapear para r√≥tulos de sentimento\n",
    "    sentiment_map = {0: \"Negativo\", 1: \"Neutro\", 2: \"Positivo\"}\n",
    "    sentiment = sentiment_map[sentiment_class]\n",
    "    \n",
    "    # Obter as probabilidades\n",
    "    probabilities = prediction[0]\n",
    "    \n",
    "    return sentiment, probabilities\n",
    "\n",
    "# Fun√ß√£o para exibir o resultado com a cor apropriada\n",
    "def display_sentiment(sentiment):\n",
    "    if sentiment == \"Positivo\":\n",
    "        return st.markdown(f'<p class=\"positive\">Sentimento: {sentiment}</p>', unsafe_allow_html=True)\n",
    "    elif sentiment == \"Neutro\":\n",
    "        return st.markdown(f'<p class=\"neutral\">Sentimento: {sentiment}</p>', unsafe_allow_html=True)\n",
    "    else:\n",
    "        return st.markdown(f'<p class=\"negative\">Sentimento: {sentiment}</p>', unsafe_allow_html=True)\n",
    "\n",
    "# Fun√ß√£o para plotar o gr√°fico de barras\n",
    "def plot_sentiment_probabilities(probabilities):\n",
    "    labels = ['Negativo', 'Neutro', 'Positivo']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    fig.patch.set_facecolor('#1E1E1E')\n",
    "    ax.set_facecolor('#1E1E1E')\n",
    "    \n",
    "    bars = ax.bar(labels, probabilities * 100, color=['#F44336', '#9E9E9E', '#4CAF50'])\n",
    "    \n",
    "    # Adicionar r√≥tulos e t√≠tulo\n",
    "    ax.set_ylabel('Probabilidade (%)', color='white')\n",
    "    ax.set_title('Distribui√ß√£o de Probabilidades de Sentimento', color='white')\n",
    "    \n",
    "    # Personalizar eixos\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['top'].set_color('white')\n",
    "    ax.spines['right'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')\n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    color='white')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Interface principal\n",
    "def main():\n",
    "    # Carregar o modelo e o tokenizer\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    \n",
    "    # T√≠tulo\n",
    "    st.markdown('<p class=\"title\">WineMood ‚Äì Sentiment Analyzer</p>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Criar abas\n",
    "    tab1, tab2 = st.tabs([\"Analisador de Sentimentos\", \"Sobre o Projeto\"])\n",
    "    \n",
    "    with tab1:\n",
    "        st.markdown('<p class=\"subtitle\">An√°lise de Sentimentos em Avalia√ß√µes de Vinhos</p>', unsafe_allow_html=True)\n",
    "        \n",
    "        # √Årea de texto para entrada do usu√°rio\n",
    "        user_input = st.text_area(\"Digite a descri√ß√£o do vinho (ou v√°rias descri√ß√µes, uma por linha):\", \n",
    "                                height=150,\n",
    "                                placeholder=\"Ex: Great complexity with floral aromas and a long finish.\")\n",
    "        \n",
    "        # Bot√£o para classificar\n",
    "        if st.button(\"Classify\"):\n",
    "            if user_input:\n",
    "                # Dividir o texto em linhas para processar m√∫ltiplas avalia√ß√µes\n",
    "                reviews = user_input.strip().split('\\n')\n",
    "                \n",
    "                # Processar cada avalia√ß√£o\n",
    "                results = []\n",
    "                all_probabilities = []\n",
    "                \n",
    "                for review in reviews:\n",
    "                    if review.strip():  # Verificar se a linha n√£o est√° vazia\n",
    "                        sentiment, probabilities = classify_sentiment(review, model, tokenizer)\n",
    "                        results.append((review, sentiment))\n",
    "                        all_probabilities.append(probabilities)\n",
    "                \n",
    "                # Exibir resultados\n",
    "                if len(results) == 1:\n",
    "                    # Caso de uma √∫nica avalia√ß√£o\n",
    "                    display_sentiment(results[0][1])\n",
    "                    \n",
    "                    # Plotar gr√°fico de probabilidades\n",
    "                    st.pyplot(plot_sentiment_probabilities(all_probabilities[0]))\n",
    "                else:\n",
    "                    # Caso de m√∫ltiplas avalia√ß√µes\n",
    "                    st.markdown('<p class=\"subtitle\">Resultados:</p>', unsafe_allow_html=True)\n",
    "                    \n",
    "                    # Criar DataFrame para exibir resultados\n",
    "                    df_results = pd.DataFrame(results, columns=['Avalia√ß√£o', 'Sentimento'])\n",
    "                    \n",
    "                    # Contar ocorr√™ncias de cada sentimento\n",
    "                    sentiment_counts = df_results['Sentimento'].value_counts()\n",
    "                    \n",
    "                    # Garantir que todos os sentimentos estejam representados\n",
    "                    for sentiment in ['Positivo', 'Neutro', 'Negativo']:\n",
    "                        if sentiment not in sentiment_counts:\n",
    "                            sentiment_counts[sentiment] = 0\n",
    "                    \n",
    "                    # Calcular percentuais\n",
    "                    total = len(results)\n",
    "                    sentiment_percentages = (sentiment_counts / total * 100).reindex(['Positivo', 'Neutro', 'Negativo'])\n",
    "                    \n",
    "                    # Exibir tabela de resultados\n",
    "                    st.dataframe(df_results, use_container_width=True)\n",
    "                    \n",
    "                    # Plotar gr√°fico de barras com percentuais\n",
    "                    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "                    fig.patch.set_facecolor('#1E1E1E')\n",
    "                    ax.set_facecolor('#1E1E1E')\n",
    "                    \n",
    "                    bars = ax.bar(['Positivo', 'Neutro', 'Negativo'], \n",
    "                                sentiment_percentages, \n",
    "                                color=['#4CAF50', '#9E9E9E', '#F44336'])\n",
    "                    \n",
    "                    # Adicionar r√≥tulos e t√≠tulo\n",
    "                    ax.set_ylabel('Percentual (%)', color='white')\n",
    "                    ax.set_title('Distribui√ß√£o de Sentimentos', color='white')\n",
    "                    \n",
    "                    # Personalizar eixos\n",
    "                    ax.spines['bottom'].set_color('white')\n",
    "                    ax.spines['top'].set_color('white')\n",
    "                    ax.spines['right'].set_color('white')\n",
    "                    ax.spines['left'].set_color('white')\n",
    "                    ax.tick_params(axis='x', colors='white')\n",
    "                    ax.tick_params(axis='y', colors='white')\n",
    "                    \n",
    "                    # Adicionar valores nas barras\n",
    "                    for bar in bars:\n",
    "                        height = bar.get_height()\n",
    "                        ax.annotate(f'{height:.1f}%',\n",
    "                                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                                    xytext=(0, 3),\n",
    "                                    textcoords=\"offset points\",\n",
    "                                    ha='center', va='bottom',\n",
    "                                    color='white')\n",
    "                    \n",
    "                    st.pyplot(fig)\n",
    "            else:\n",
    "                st.warning(\"Por favor, digite uma avalia√ß√£o de vinho para classificar.\")\n",
    "    \n",
    "    with tab2:\n",
    "        st.markdown('<p class=\"subtitle\">Sobre o WineMood</p>', unsafe_allow_html=True)\n",
    "        \n",
    "        st.markdown(\"\"\"\n",
    "        ## O que √© o WineMood?\n",
    "        \n",
    "        WineMood √© um sistema inteligente que analisa avalia√ß√µes textuais de vinhos e classifica automaticamente o sentimento expresso como positivo, neutro ou negativo. Utilizando t√©cnicas de Processamento de Linguagem Natural (NLP) combinadas com Deep Learning, o projeto transforma a linguagem humana em insights √∫teis para consumidores e empresas.\n",
    "        \n",
    "        ## Como funciona?\n",
    "        \n",
    "        O sistema utiliza um modelo de Deep Learning baseado em redes neurais recorrentes (LSTM) para entender o contexto e o sentimento das avalia√ß√µes de vinhos. O processo inclui:\n",
    "        \n",
    "        1. **Pr√©-processamento de texto**: limpeza, remo√ß√£o de stopwords e tokeniza√ß√£o\n",
    "        2. **Vetoriza√ß√£o**: convers√£o de palavras em representa√ß√µes num√©ricas\n",
    "        3. **An√°lise de sequ√™ncia**: compreens√£o do contexto atrav√©s de LSTM\n",
    "        4. **Classifica√ß√£o**: determina√ß√£o do sentimento predominante\n",
    "        \n",
    "        ## Aplica√ß√µes pr√°ticas\n",
    "        \n",
    "        - Recomenda√ß√£o autom√°tica de vinhos com base no sentimento do cliente\n",
    "        - Aux√≠lio a vendedores e produtores de vinho para entender a percep√ß√£o do p√∫blico\n",
    "        - Destaque de vinhos bem avaliados em plataformas de e-commerce\n",
    "        \n",
    "        ## Tecnologias utilizadas\n",
    "        \n",
    "        - **Python**: linguagem de programa√ß√£o principal\n",
    "        - **TensorFlow + Keras**: framework de Deep Learning\n",
    "        - **NLTK**: biblioteca para processamento de linguagem natural\n",
    "        - **Streamlit**: interface web interativa\n",
    "        - **Pandas & NumPy**: manipula√ß√£o de dados\n",
    "        - **Matplotlib**: visualiza√ß√£o de dados\n",
    "        \n",
    "        ## Dataset\n",
    "        \n",
    "        O modelo foi treinado com aproximadamente 130.000 avalia√ß√µes de vinhos do Kaggle, com pontua√ß√µes convertidas em categorias de sentimento:\n",
    "        \n",
    "        - **Positivo**: pontua√ß√£o ‚â• 90\n",
    "        - **Neutro**: pontua√ß√£o entre 80-89\n",
    "        - **Negativo**: pontua√ß√£o < 80\n",
    "        \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Instru√ß√µes para Deploy\n",
    "\n",
    "### Deploy Local\n",
    "\n",
    "Para executar a aplica√ß√£o localmente:\n",
    "\n",
    "1. Instale as depend√™ncias: `pip install -r requirements.txt`\n",
    "2. Execute o Streamlit: `streamlit run app.py`\n",
    "\n",
    "### Deploy no Streamlit Cloud\n",
    "\n",
    "Para fazer o deploy no Streamlit Cloud:\n",
    "\n",
    "1. Crie uma conta no [Streamlit Cloud](https://streamlit.io/cloud)\n",
    "2. Crie um reposit√≥rio no GitHub com os seguintes arquivos:\n",
    "   - app.py\n",
    "   - requirements.txt\n",
    "   - model.h5\n",
    "   - tokenizer.pickle\n",
    "3. Conecte o reposit√≥rio ao Streamlit Cloud\n",
    "4. Configure o deploy com o arquivo principal como app.py\n",
    "\n",
    "## 13. Conclus√£o\n",
    "\n",
    "Neste notebook, desenvolvemos um classificador de sentimentos para avalia√ß√µes de vinhos usando Deep Learning. O modelo alcan√ßou uma boa acur√°cia e foi implementado em uma interface web interativa usando Streamlit.\n",
    "\n",
    "O projeto WineMood demonstra como t√©cnicas de NLP e Deep Learning podem ser aplicadas a dados do mundo real para extrair insights valiosos e criar aplica√ß√µes pr√°ticas para consumidores e empresas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
